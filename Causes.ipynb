{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3bb2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers.models.bert import BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175c58ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>Problème R.P non éffectué ===.=&gt; Intervention ...</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>reparation defaut tension du convoyeur sortie ...</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>Réparation défaut moteur d'extracteur  poudrag...</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>changement maille</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>changement projecteur led au niveau extérieur ...</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5160</th>\n",
       "      <td>Correction de decor</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>réglage tension tapis posimat</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>changement distribiteur monte et baisse bras l...</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>Décherire plastique au niveau barre de soudure</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>demontage pompe et changement garniture</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5407</th>\n",
       "      <td>Défaut lecture réfractomètre de peroxyde===&gt;ha...</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>reparation fuite d'eau au niveau flexible de n...</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6372</th>\n",
       "      <td>Changement dolly + roues contre pression</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>Réglage d'air + lame suite problème décoletage...</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>changement teflon barre de soudure</td>\n",
       "      <td>Mécanique</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Description      label\n",
       "2627  Problème R.P non éffectué ===.=> Intervention ...  Mécanique\n",
       "876   reparation defaut tension du convoyeur sortie ...  Mécanique\n",
       "3564  Réparation défaut moteur d'extracteur  poudrag...  Mécanique\n",
       "2161                                  changement maille  Mécanique\n",
       "751   changement projecteur led au niveau extérieur ...  Mécanique\n",
       "5160                                Correction de decor  Mécanique\n",
       "4277                     réglage tension tapis posimat   Mécanique\n",
       "4785  changement distribiteur monte et baisse bras l...  Mécanique\n",
       "2305    Décherire plastique au niveau barre de soudure   Mécanique\n",
       "3070            demontage pompe et changement garniture  Mécanique\n",
       "5407  Défaut lecture réfractomètre de peroxyde===>ha...  Mécanique\n",
       "4225  reparation fuite d'eau au niveau flexible de n...  Mécanique\n",
       "6372           Changement dolly + roues contre pression  Mécanique\n",
       "3909  Réglage d'air + lame suite problème décoletage...  Mécanique\n",
       "6204                 changement teflon barre de soudure  Mécanique"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('./CleanData.csv')\n",
    "data = data[ ['Description','Classification_Equipement']]\n",
    "data = data.rename(columns={'Classification_Equipement': 'label'})\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1068f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4627bfe51241c6bd663347ae7552a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5218 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f95b4e15bf4c0894e053769e7198e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Description': 'reparation defaut disjoncteursuite defaut demande produit', 'label': 2, 'input_ids': [101, 16360, 25879, 3258, 13366, 4887, 2102, 4487, 2015, 14339, 6593, 26744, 14663, 2063, 13366, 4887, 2102, 5157, 2063, 4013, 8566, 4183, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 2}\n",
      "Number of classes: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load and prepare data\n",
    "data = pd.read_csv('./CleanData.csv')\n",
    "data = data[['Description', 'Classification_Equipement']]\n",
    "data = data.rename(columns={'Classification_Equipement': 'label'})\n",
    "\n",
    "# 2. Initialize tokenizer BEFORE defining the tokenize function\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 3. Convert text labels to numerical values\n",
    "le = LabelEncoder()\n",
    "data['label'] = le.fit_transform(data['label'])\n",
    "\n",
    "# 4. Define tokenize function (now it can access the tokenizer)\n",
    "def tokenize(batch):\n",
    "    encoding = tokenizer(batch['Description'], padding=True, truncation=True, max_length=512)\n",
    "    encoding['labels'] = batch['label']  # Add numerical labels\n",
    "    return encoding\n",
    "\n",
    "# 5. Create dataset and split\n",
    "dataset = Dataset.from_pandas(data)\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# 6. Apply tokenization\n",
    "encoded_dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# 7. Verify label format\n",
    "print(encoded_dataset['train'][0])  # Check structure\n",
    "print(\"Number of classes:\", len(le.classes_))\n",
    "\n",
    "# 8. Initialize model\n",
    "num_labels = len(le.classes_)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "# Rest of your training code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6241d3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(data['label'].unique())\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=num_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4666be77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15500\\40971357.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    " output_dir=\"./quick_results\",\n",
    "    eval_steps=100,                  # Evaluate every 100 steps\n",
    "    save_strategy=\"no\",              # Disable model saving to save time\n",
    "    per_device_train_batch_size=32,   # Increased batch size\n",
    "    per_device_eval_batch_size=64,    # Larger eval batch\n",
    "    num_train_epochs=1,               # Only 1 epoch\n",
    "    max_steps=500,                    # Limit total steps\n",
    "    logging_steps=50,\n",
    "    learning_rate=3e-5,\n",
    "    warmup_steps=50,\n",
    "    fp16=True,                        # Enable mixed precision training\n",
    "    gradient_accumulation_steps=2,     # Effective batch size = 64\n",
    "    report_to=\"none\",   \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset['train'],\n",
    "    eval_dataset=encoded_dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\nlp_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/500 : < :, Epoch 0.01/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d6c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"CHANGEMENT POMPE A EAU\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = model(**inputs)\n",
    "prediction = outputs.logits.argmax(dim=1).item()\n",
    "\n",
    "print(f\"Predicted class: {prediction}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
